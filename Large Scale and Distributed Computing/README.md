# Foundations of Large Scale and Distributed Computing

This repository contains course materials, practical assignments, and resources for the Foundations of Large Scale and Distributed Computing course at MVA (Mathematics, Vision, Learning).

## Course Overview

This course covers fundamental concepts and advanced techniques in large-scale and distributed computing, focusing on:

- Distributed algorithms and systems
- Parallel computing paradigms
- Optimization methods for large-scale problems
- Scalable machine learning techniques
- High-performance computing

## Repository Contents


### Practical Assignments

- `TP n1.ipynb`: Practical Work 1 - Introduction to distributed computing concepts
- `TP nÂ°2_MarceauPAILHAS.ipynb`: Practical Work 2 - Implementation of distributed algorithms
- `LSD_TPn3_GORCEIX_PAILHAS.ipynb`: Completed assignment 3 with solutions (by GORCEIX and PAILHAS)



## Key Topics Covered

1. **Distributed Algorithms**
   - Consensus algorithms
   - Distributed optimization
   - Fault tolerance

2. **Large-Scale Optimization**
   - Gradient descent methods
   - Stochastic optimization
   - Proximal methods
   - Coordinate descent

3. **Parallel Computing**
   - MapReduce paradigm
   - Parallel processing frameworks
   - Synchronous vs. asynchronous methods

4. **Applications**
   - Distributed machine learning
   - Large-scale data processing
   - High-dimensional optimization problems

## Requirements

To run the Jupyter notebooks in this repository, you'll need:

- Python 3.x
- Jupyter Notebook or JupyterLab
- NumPy, SciPy, Matplotlib
- MATLAB (optional, for working with .mat files)

## Usage

1. Clone or download this repository
2. Install the required dependencies
3. Open the Jupyter notebooks to explore the practical assignments
4. Refer to the PDF documents for theoretical background and course materials

## References

The course materials and assignments are based on current research and established techniques in the field of large-scale and distributed computing.
